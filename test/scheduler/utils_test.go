/*
Copyright (c) Microsoft Corporation.
Licensed under the MIT license.
*/

package tests

// This file features utilities used in the test suites.

import (
	"strconv"
	"time"

	"github.com/google/go-cmp/cmp"
	"github.com/google/go-cmp/cmp/cmpopts"
	. "github.com/onsi/gomega"
	rbacv1 "k8s.io/api/rbac/v1"
	"k8s.io/apimachinery/pkg/api/errors"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/labels"
	"k8s.io/apimachinery/pkg/types"
	"k8s.io/client-go/rest"
	"k8s.io/client-go/tools/clientcmd"
	clientcmdapi "k8s.io/client-go/tools/clientcmd/api"
	"k8s.io/utils/ptr"
	"sigs.k8s.io/controller-runtime/pkg/client"
	"sigs.k8s.io/controller-runtime/pkg/manager"

	clusterv1beta1 "go.goms.io/fleet/apis/cluster/v1beta1"
	placementv1beta1 "go.goms.io/fleet/apis/placement/v1beta1"
	"go.goms.io/fleet/pkg/scheduler/clustereligibilitychecker"
	"go.goms.io/fleet/pkg/scheduler/framework"
	"go.goms.io/fleet/pkg/scheduler/framework/plugins/clusteraffinity"
	"go.goms.io/fleet/pkg/scheduler/framework/plugins/clustereligibility"
	"go.goms.io/fleet/pkg/scheduler/framework/plugins/sameplacementaffinity"
	"go.goms.io/fleet/pkg/scheduler/framework/plugins/topologyspreadconstraints"
)

// This file features some utilities used in the test suites.

const (
	crpNameTemplate                = "crp-%d"
	policySnapshotNameTemplate     = "%s-policy-snapshot-%d"
	provisionalClusterNameTemplate = "provisional-cluster-%d"

	policyHash = "policy-hash"

	bindingNamePlaceholder = "binding"
)

var (
	// Note that for the scheduler integration tests, since no actual resources are collected
	// by any controller (the scheduler cares only about policy snapshots and manipulates
	// bindings accordingly), it is safe for all suites to select the same set of resources
	// (which is not even provisioned in the environment).
	defaultResourceSelectors = []placementv1beta1.ClusterResourceSelector{
		{
			Group:   "core",
			Kind:    "Namespace",
			Version: "v1",
			Name:    "work",
		},
	}

	nilScoreByCluster = map[string]*placementv1beta1.ClusterScore{}
	zeroScore         = placementv1beta1.ClusterScore{
		AffinityScore:       ptr.To(int32(0)),
		TopologySpreadScore: ptr.To(int32(0)),
	}
	zeroScoreByCluster = map[string]*placementv1beta1.ClusterScore{
		memberCluster1EastProd:          &zeroScore,
		memberCluster2EastProd:          &zeroScore,
		memberCluster3EastCanary:        &zeroScore,
		memberCluster4CentralProd:       &zeroScore,
		memberCluster5CentralProd:       &zeroScore,
		memberCluster6WestProd:          &zeroScore,
		memberCluster7WestCanary:        &zeroScore,
		memberCluster8UnhealthyEastProd: &zeroScore,
		memberCluster9LeftCentralProd:   &zeroScore,
	}
)

var (
	lessFuncBinding = func(binding1, binding2 placementv1beta1.ClusterResourceBinding) bool {
		return binding1.Spec.TargetCluster < binding2.Spec.TargetCluster
	}
	lessFuncClusterDecision = func(decision1, decision2 placementv1beta1.ClusterDecision) bool {
		return decision1.ClusterName < decision2.ClusterName
	}

	ignoreClusterDecisionReasonField          = cmpopts.IgnoreFields(placementv1beta1.ClusterDecision{}, "Reason")
	ignoreObjectMetaNameField                 = cmpopts.IgnoreFields(metav1.ObjectMeta{}, "Name")
	ignoreObjectMetaAnnotationField           = cmpopts.IgnoreFields(metav1.ObjectMeta{}, "Annotations")
	ignoreObjectMetaAutoGeneratedFields       = cmpopts.IgnoreFields(metav1.ObjectMeta{}, "UID", "CreationTimestamp", "ResourceVersion", "Generation", "ManagedFields")
	ignoreResourceBindingTypeMetaField        = cmpopts.IgnoreFields(placementv1beta1.ClusterResourceBinding{}, "TypeMeta")
	ignoreConditionTimeReasonAndMessageFields = cmpopts.IgnoreFields(metav1.Condition{}, "LastTransitionTime", "Reason", "Message")

	ignoreResourceBindingFields = []cmp.Option{
		ignoreResourceBindingTypeMetaField,
		ignoreObjectMetaNameField,
		ignoreObjectMetaAnnotationField,
		ignoreObjectMetaAutoGeneratedFields,
		ignoreClusterDecisionReasonField,
		cmpopts.SortSlices(lessFuncBinding),
	}
)

func buildSchedulerFramework(ctrlMgr manager.Manager, clusterEligibilityChecker *clustereligibilitychecker.ClusterEligibilityChecker) framework.Framework {
	// Create a new profile.
	profile := framework.NewProfile(defaultProfileName)

	// Register the plugins.
	clusterAffinityPlugin := clusteraffinity.New()
	clustereligibilityPlugin := clustereligibility.New()
	samePlacementAffinityPlugin := sameplacementaffinity.New()
	topologyspreadconstraintsPlugin := topologyspreadconstraints.New()
	profile.
		// Register cluster affinity plugin.
		WithPreFilterPlugin(&clusterAffinityPlugin).
		WithFilterPlugin(&clusterAffinityPlugin).
		WithPreScorePlugin(&clusterAffinityPlugin).
		WithScorePlugin(&clusterAffinityPlugin).
		// Register cluster eligibility plugin.
		WithFilterPlugin(&clustereligibilityPlugin).
		// Register same placement affinity plugin.
		WithFilterPlugin(&samePlacementAffinityPlugin).
		WithScorePlugin(&samePlacementAffinityPlugin).
		// Register topology spread constraints plugin.
		WithPostBatchPlugin(&topologyspreadconstraintsPlugin).
		WithPreFilterPlugin(&topologyspreadconstraintsPlugin).
		WithFilterPlugin(&topologyspreadconstraintsPlugin).
		WithPreScorePlugin(&topologyspreadconstraintsPlugin).
		WithScorePlugin(&topologyspreadconstraintsPlugin)

	// Create a scheduler framework.
	return framework.NewFramework(profile, ctrlMgr, framework.WithClusterEligibilityChecker(clusterEligibilityChecker))
}

func buildK8sAPIConfigFrom(restCfg *rest.Config) []byte {
	clusterName := "default-cluster"
	contextName := "default-context"
	userName := "admin"

	clusters := make(map[string]*clientcmdapi.Cluster)
	clusters[clusterName] = &clientcmdapi.Cluster{
		Server:                   restCfg.Host,
		CertificateAuthorityData: restCfg.CAData,
	}

	contexts := make(map[string]*clientcmdapi.Context)
	contexts[contextName] = &clientcmdapi.Context{
		Cluster:  clusterName,
		AuthInfo: userName,
	}

	authInfos := make(map[string]*clientcmdapi.AuthInfo)
	authInfos[userName] = &clientcmdapi.AuthInfo{
		ClientCertificateData: restCfg.CertData,
		ClientKeyData:         restCfg.KeyData,
	}

	apiCfg := &clientcmdapi.Config{
		Kind:           "Config",
		APIVersion:     "v1",
		Clusters:       clusters,
		Contexts:       contexts,
		CurrentContext: contextName,
		AuthInfos:      authInfos,
	}

	apiCfgBytes, err := clientcmd.Write(*apiCfg)
	Expect(err).To(BeNil(), "Failed to write API config")
	return apiCfgBytes
}

func loadRestConfigFrom(apiCfgBytes []byte) *rest.Config {
	apiCfg, err := clientcmd.Load(apiCfgBytes)
	Expect(err).To(BeNil(), "Failed to load API config")

	restCfg, err := clientcmd.NewDefaultClientConfig(*apiCfg, &clientcmd.ConfigOverrides{}).ClientConfig()
	Expect(err).To(BeNil(), "Failed to load REST config")

	return restCfg
}

func createMemberCluster(name string) {
	memberCluster := clusterv1beta1.MemberCluster{
		ObjectMeta: metav1.ObjectMeta{
			Name: name,
		},
		Spec: clusterv1beta1.MemberClusterSpec{
			Identity: rbacv1.Subject{
				Kind:     "ServiceAccount",
				APIGroup: "",
				Name:     "admin",
			},
		},
	}
	Expect(hubClient.Create(ctx, &memberCluster)).To(Succeed(), "Failed to create member cluster")
}

func markClusterAsHealthy(name string) {
	memberCluster := clusterv1beta1.MemberCluster{}
	Expect(hubClient.Get(ctx, types.NamespacedName{Name: name}, &memberCluster)).To(Succeed(), "Failed to get member cluster")
	memberCluster.Status.AgentStatus = []clusterv1beta1.AgentStatus{
		{
			Type: clusterv1beta1.MemberAgent,
			Conditions: []metav1.Condition{
				{
					Type:               string(clusterv1beta1.AgentJoined),
					Status:             metav1.ConditionTrue,
					LastTransitionTime: metav1.NewTime(time.Now()),
					Reason:             dummyReason,
				},
				{
					Type:               string(clusterv1beta1.AgentHealthy),
					Status:             metav1.ConditionTrue,
					LastTransitionTime: metav1.NewTime(time.Now()),
					Reason:             dummyReason,
				},
			},
			LastReceivedHeartbeat: metav1.NewTime(time.Now()),
		},
	}
	Expect(hubClient.Status().Update(ctx, &memberCluster)).To(Succeed(), "Failed to update member cluster status")
}

func markClusterAsUnhealthy(name string) {
	memberCluster := clusterv1beta1.MemberCluster{}
	Expect(hubClient.Get(ctx, types.NamespacedName{Name: name}, &memberCluster)).To(Succeed(), "Failed to get member cluster")
	memberCluster.Status.AgentStatus = []clusterv1beta1.AgentStatus{
		{
			Type: clusterv1beta1.MemberAgent,
			Conditions: []metav1.Condition{
				{
					Type:               string(clusterv1beta1.AgentJoined),
					Status:             metav1.ConditionTrue,
					LastTransitionTime: metav1.NewTime(time.Now().Add(-time.Hour * 25)),
					Reason:             dummyReason,
				},
				{
					Type:               string(clusterv1beta1.AgentHealthy),
					Status:             metav1.ConditionTrue,
					LastTransitionTime: metav1.NewTime(time.Now().Add(-time.Hour * 25)),
					Reason:             dummyReason,
				},
			},
			LastReceivedHeartbeat: metav1.NewTime(time.Now().Add(-time.Hour * 25)),
		},
	}
	Expect(hubClient.Status().Update(ctx, &memberCluster)).To(Succeed(), "Failed to update member cluster status")
}

func createPickFixedCRPWithPolicySnapshot(crpName string, targetClusters []string, policySnapshotName string) {
	policy := &placementv1beta1.PlacementPolicy{
		PlacementType: placementv1beta1.PickFixedPlacementType,
		ClusterNames:  targetClusters,
	}

	// Create the CRP.
	crp := &placementv1beta1.ClusterResourcePlacement{
		ObjectMeta: metav1.ObjectMeta{
			Name:       crpName,
			Finalizers: []string{customDeletionBlockerFinalizer},
		},
		Spec: placementv1beta1.ClusterResourcePlacementSpec{
			ResourceSelectors: defaultResourceSelectors,
			Policy:            policy,
		},
	}
	Expect(hubClient.Create(ctx, crp)).To(Succeed(), "Failed to create CRP")

	crpGeneration := crp.Generation

	// Create the associated policy snapshot.
	policySnapshot := &placementv1beta1.ClusterSchedulingPolicySnapshot{
		ObjectMeta: metav1.ObjectMeta{
			Name: policySnapshotName,
			Labels: map[string]string{
				placementv1beta1.IsLatestSnapshotLabel: strconv.FormatBool(true),
				placementv1beta1.CRPTrackingLabel:      crpName,
			},
			Annotations: map[string]string{
				placementv1beta1.CRPGenerationAnnotation: strconv.FormatInt(crpGeneration, 10),
			},
		},
		Spec: placementv1beta1.SchedulingPolicySnapshotSpec{
			Policy:     policy,
			PolicyHash: []byte(policyHash),
		},
	}
	Expect(hubClient.Create(ctx, policySnapshot)).To(Succeed(), "Failed to create policy snapshot")
}

func createNilSchedulingPolicyCRPWithPolicySnapshot(crpName string, policySnapshotName string) {
	// Create a CRP with no scheduling policy specified.
	crp := placementv1beta1.ClusterResourcePlacement{
		ObjectMeta: metav1.ObjectMeta{
			Name:       crpName,
			Finalizers: []string{customDeletionBlockerFinalizer},
		},
		Spec: placementv1beta1.ClusterResourcePlacementSpec{
			ResourceSelectors: defaultResourceSelectors,
			Policy:            nil,
		},
	}
	Expect(hubClient.Create(ctx, &crp)).Should(Succeed(), "Failed to create CRP")

	crpGeneration := crp.Generation

	// Create the associated policy snapshot.
	policySnapshot := &placementv1beta1.ClusterSchedulingPolicySnapshot{
		ObjectMeta: metav1.ObjectMeta{
			Name: policySnapshotName,
			Labels: map[string]string{
				placementv1beta1.IsLatestSnapshotLabel: strconv.FormatBool(true),
				placementv1beta1.CRPTrackingLabel:      crpName,
			},
			Annotations: map[string]string{
				placementv1beta1.CRPGenerationAnnotation: strconv.FormatInt(crpGeneration, 10),
			},
		},
		Spec: placementv1beta1.SchedulingPolicySnapshotSpec{
			Policy:     nil,
			PolicyHash: []byte(policyHash),
		},
	}
	Expect(hubClient.Create(ctx, policySnapshot)).Should(Succeed(), "Failed to create policy snapshot")
}

func updatePickFixedCRPWithNewTargetClustersAndRefreshSnapshots(crpName string, targetClusters []string, oldPolicySnapshotName, newPolicySnapshotName string) {
	// Update the CRP.
	crp := &placementv1beta1.ClusterResourcePlacement{}
	Expect(hubClient.Get(ctx, types.NamespacedName{Name: crpName}, crp)).To(Succeed(), "Failed to get CRP")

	policy := crp.Spec.Policy.DeepCopy()
	policy.ClusterNames = targetClusters
	crp.Spec.Policy = policy
	Expect(hubClient.Update(ctx, crp)).To(Succeed(), "Failed to update CRP")

	crpGeneration := crp.Generation

	// Mark the old policy snapshot as inactive.
	policySnapshot := &placementv1beta1.ClusterSchedulingPolicySnapshot{}
	Expect(hubClient.Get(ctx, types.NamespacedName{Name: oldPolicySnapshotName}, policySnapshot)).To(Succeed(), "Failed to get policy snapshot")
	policySnapshot.Labels[placementv1beta1.IsLatestSnapshotLabel] = strconv.FormatBool(false)
	Expect(hubClient.Update(ctx, policySnapshot)).To(Succeed(), "Failed to update policy snapshot")

	// Create a new policy snapshot.
	policySnapshot = &placementv1beta1.ClusterSchedulingPolicySnapshot{
		ObjectMeta: metav1.ObjectMeta{
			Name: newPolicySnapshotName,
			Labels: map[string]string{
				placementv1beta1.IsLatestSnapshotLabel: strconv.FormatBool(true),
				placementv1beta1.CRPTrackingLabel:      crpName,
			},
			Annotations: map[string]string{
				placementv1beta1.CRPGenerationAnnotation: strconv.FormatInt(crpGeneration, 10),
			},
		},
		Spec: placementv1beta1.SchedulingPolicySnapshotSpec{
			Policy:     policy,
			PolicyHash: []byte(policyHash),
		},
	}
	Expect(hubClient.Create(ctx, policySnapshot)).To(Succeed(), "Failed to create policy snapshot")
}

func markBindingsAsBoundForClusters(crpName string, boundClusters []string) {
	bindingList := &placementv1beta1.ClusterResourceBindingList{}
	labelSelector := labels.SelectorFromSet(labels.Set{placementv1beta1.CRPTrackingLabel: crpName})
	listOptions := &client.ListOptions{LabelSelector: labelSelector}
	Expect(hubClient.List(ctx, bindingList, listOptions)).To(Succeed(), "Failed to list bindings")
	boundClusterMap := make(map[string]bool)
	for _, cluster := range boundClusters {
		boundClusterMap[cluster] = true
	}
	for idx := range bindingList.Items {
		binding := bindingList.Items[idx]
		if _, ok := boundClusterMap[binding.Spec.TargetCluster]; ok && binding.Spec.State == placementv1beta1.BindingStateScheduled {
			binding.Spec.State = placementv1beta1.BindingStateBound
			Expect(hubClient.Update(ctx, &binding)).To(Succeed(), "Failed to update binding")
		}
	}
}

func ensureCRPAndAllRelatedResourcesDeletion(crpName string) {
	// Delete the CRP.
	crp := &placementv1beta1.ClusterResourcePlacement{
		ObjectMeta: metav1.ObjectMeta{
			Name: crpName,
		},
	}
	Expect(hubClient.Delete(ctx, crp)).To(Succeed(), "Failed to delete CRP")

	// Ensure that all the bindings are deleted.
	noBindingsCreatedActual := noBindingsCreatedForCRPActual(crpName)
	Eventually(noBindingsCreatedActual, eventuallyDuration, eventuallyInterval).Should(Succeed(), "Failed to clear all bindings")
	Consistently(noBindingsCreatedActual, consistentlyDuration, consistentlyInterval).Should(Succeed(), "Failed to clear all bindings")

	// Ensure that the scheduler finalizer is removed.
	finalizerRemovedActual := crpSchedulerFinalizerRemovedActual(crpName)
	Eventually(finalizerRemovedActual, eventuallyDuration, eventuallyInterval).Should(Succeed(), "Failed to remove scheduler cleanup finalizer from CRP")

	// Remove all the other finalizers from the CRP.
	Eventually(func() error {
		crp := &placementv1beta1.ClusterResourcePlacement{}
		if err := hubClient.Get(ctx, types.NamespacedName{Name: crpName}, crp); err != nil {
			return err
		}

		crp.Finalizers = []string{}
		return hubClient.Update(ctx, crp)
	}, eventuallyDuration, eventuallyInterval).Should(Succeed(), "Failed to remove all finalizers from CRP")

	// Ensure that the CRP is deleted.
	Eventually(func() error {
		err := hubClient.Get(ctx, types.NamespacedName{Name: crpName}, &placementv1beta1.ClusterResourcePlacement{})
		if errors.IsNotFound(err) {
			return nil
		}

		return err
	}, eventuallyDuration, eventuallyInterval).Should(Succeed(), "Failed to delete CRP")

	// List all policy snapshots.
	policySnapshotList := &placementv1beta1.ClusterSchedulingPolicySnapshotList{}
	labelSelector := labels.SelectorFromSet(labels.Set{placementv1beta1.CRPTrackingLabel: crpName})
	listOptions := &client.ListOptions{LabelSelector: labelSelector}
	Expect(hubClient.List(ctx, policySnapshotList, listOptions)).To(Succeed(), "Failed to list policy snapshots")

	// Delete all policy snapshots and ensure their deletion.
	for idx := range policySnapshotList.Items {
		policySnapshot := policySnapshotList.Items[idx]
		Expect(hubClient.Delete(ctx, &policySnapshot)).To(Succeed(), "Failed to delete policy snapshot")

		Eventually(func() error {
			err := hubClient.Get(ctx, types.NamespacedName{Name: policySnapshot.Name}, &placementv1beta1.ClusterSchedulingPolicySnapshot{})
			if errors.IsNotFound(err) {
				return nil
			}

			return err
		}, eventuallyDuration, eventuallyInterval).Should(Succeed(), "Failed to delete policy snapshot")
	}
}

func ensureProvisionalClusterDeletion(clusterName string) {
	// Retrieve the provisional cluster.
	memberCluster := &clusterv1beta1.MemberCluster{
		ObjectMeta: metav1.ObjectMeta{
			Name: clusterName,
		},
	}
	Expect(hubClient.Delete(ctx, memberCluster)).To(Succeed(), "Failed to delete member cluster")

	// Ensure that the provisional cluster is deleted.
	Eventually(func() error {
		err := hubClient.Get(ctx, types.NamespacedName{Name: clusterName}, &clusterv1beta1.MemberCluster{})
		if errors.IsNotFound(err) {
			return nil
		}

		return err
	}, eventuallyDuration, eventuallyInterval).Should(Succeed(), "Failed to delete member cluster")
}

func createPickAllCRPWithPolicySnapshot(crpName string, affinity *placementv1beta1.Affinity, policySnapshotName string) {
	policy := &placementv1beta1.PlacementPolicy{
		PlacementType: placementv1beta1.PickAllPlacementType,
		Affinity:      affinity,
	}

	// Create a CRP of the PickAll placement type.
	crp := placementv1beta1.ClusterResourcePlacement{
		ObjectMeta: metav1.ObjectMeta{
			Name:       crpName,
			Finalizers: []string{customDeletionBlockerFinalizer},
		},
		Spec: placementv1beta1.ClusterResourcePlacementSpec{
			ResourceSelectors: defaultResourceSelectors,
			Policy:            policy,
		},
	}
	Expect(hubClient.Create(ctx, &crp)).Should(Succeed(), "Failed to create CRP")

	crpGeneration := crp.Generation

	// Create the associated policy snapshot.
	policySnapshot := &placementv1beta1.ClusterSchedulingPolicySnapshot{
		ObjectMeta: metav1.ObjectMeta{
			Name: policySnapshotName,
			Labels: map[string]string{
				placementv1beta1.IsLatestSnapshotLabel: strconv.FormatBool(true),
				placementv1beta1.CRPTrackingLabel:      crpName,
			},
			Annotations: map[string]string{
				placementv1beta1.CRPGenerationAnnotation: strconv.FormatInt(crpGeneration, 10),
			},
		},
		Spec: placementv1beta1.SchedulingPolicySnapshotSpec{
			Policy:     policy,
			PolicyHash: []byte(policyHash),
		},
	}
	Expect(hubClient.Create(ctx, policySnapshot)).Should(Succeed(), "Failed to create policy snapshot")
}

func updatePickAllCRPWithNewAffinity(crpName string, affinity *placementv1beta1.Affinity, oldPolicySnapshotName, newPolicySnapshotName string) {
	// Update the CRP.
	crp := &placementv1beta1.ClusterResourcePlacement{}
	Expect(hubClient.Get(ctx, types.NamespacedName{Name: crpName}, crp)).To(Succeed(), "Failed to get CRP")

	policy := crp.Spec.Policy.DeepCopy()
	policy.Affinity = affinity
	crp.Spec.Policy = policy
	Expect(hubClient.Update(ctx, crp)).To(Succeed(), "Failed to update CRP")

	crpGeneration := crp.Generation

	// Mark the old policy snapshot as inactive.
	policySnapshot := &placementv1beta1.ClusterSchedulingPolicySnapshot{}
	Expect(hubClient.Get(ctx, types.NamespacedName{Name: oldPolicySnapshotName}, policySnapshot)).To(Succeed(), "Failed to get policy snapshot")
	policySnapshot.Labels[placementv1beta1.IsLatestSnapshotLabel] = strconv.FormatBool(false)
	Expect(hubClient.Update(ctx, policySnapshot)).To(Succeed(), "Failed to update policy snapshot")

	// Create a new policy snapshot.
	policySnapshot = &placementv1beta1.ClusterSchedulingPolicySnapshot{
		ObjectMeta: metav1.ObjectMeta{
			Name: newPolicySnapshotName,
			Labels: map[string]string{
				placementv1beta1.IsLatestSnapshotLabel: strconv.FormatBool(true),
				placementv1beta1.CRPTrackingLabel:      crpName,
			},
			Annotations: map[string]string{
				placementv1beta1.CRPGenerationAnnotation: strconv.FormatInt(crpGeneration, 10),
			},
		},
		Spec: placementv1beta1.SchedulingPolicySnapshotSpec{
			Policy:     policy,
			PolicyHash: []byte(policyHash),
		},
	}
	Expect(hubClient.Create(ctx, policySnapshot)).To(Succeed(), "Failed to create policy snapshot")
}

func createPickNCRPWithPolicySnapshot(
	crpName string,
	numOfClusters int32,
	affinity *placementv1beta1.Affinity,
	topologySpreadConstraints []placementv1beta1.TopologySpreadConstraint,
	policySnapshotName string,
) {
	policy := &placementv1beta1.PlacementPolicy{
		PlacementType:             placementv1beta1.PickNPlacementType,
		NumberOfClusters:          &numOfClusters,
		Affinity:                  affinity,
		TopologySpreadConstraints: topologySpreadConstraints,
	}

	// Create a CRP of the PickAll placement type.
	crp := placementv1beta1.ClusterResourcePlacement{
		ObjectMeta: metav1.ObjectMeta{
			Name:       crpName,
			Finalizers: []string{customDeletionBlockerFinalizer},
		},
		Spec: placementv1beta1.ClusterResourcePlacementSpec{
			ResourceSelectors: defaultResourceSelectors,
			Policy:            policy,
		},
	}
	Expect(hubClient.Create(ctx, &crp)).Should(Succeed(), "Failed to create CRP")

	crpGeneration := crp.Generation

	// Create the associated policy snapshot.
	policySnapshot := &placementv1beta1.ClusterSchedulingPolicySnapshot{
		ObjectMeta: metav1.ObjectMeta{
			Name: policySnapshotName,
			Labels: map[string]string{
				placementv1beta1.IsLatestSnapshotLabel: strconv.FormatBool(true),
				placementv1beta1.CRPTrackingLabel:      crpName,
			},
			Annotations: map[string]string{
				placementv1beta1.CRPGenerationAnnotation:    strconv.FormatInt(crpGeneration, 10),
				placementv1beta1.NumberOfClustersAnnotation: strconv.FormatInt(int64(numOfClusters), 10),
			},
		},
		Spec: placementv1beta1.SchedulingPolicySnapshotSpec{
			Policy:     policy,
			PolicyHash: []byte(policyHash),
		},
	}
	Expect(hubClient.Create(ctx, policySnapshot)).Should(Succeed(), "Failed to create policy snapshot")
}

func updatePickNCRPWithNewAffinityAndTopologySpreadConstraints(
	crpName string,
	affinity *placementv1beta1.Affinity,
	topologySpreadConstraints []placementv1beta1.TopologySpreadConstraint,
	oldPolicySnapshotName, newPolicySnapshotName string,
) {
	// Update the CRP.
	crp := &placementv1beta1.ClusterResourcePlacement{}
	Expect(hubClient.Get(ctx, types.NamespacedName{Name: crpName}, crp)).To(Succeed(), "Failed to get CRP")

	policy := crp.Spec.Policy.DeepCopy()
	numOfClusters := policy.NumberOfClusters
	policy.Affinity = affinity
	policy.TopologySpreadConstraints = topologySpreadConstraints
	crp.Spec.Policy = policy
	Expect(hubClient.Update(ctx, crp)).To(Succeed(), "Failed to update CRP")

	crpGeneration := crp.Generation

	// Mark the old policy snapshot as inactive.
	policySnapshot := &placementv1beta1.ClusterSchedulingPolicySnapshot{}
	Expect(hubClient.Get(ctx, types.NamespacedName{Name: oldPolicySnapshotName}, policySnapshot)).To(Succeed(), "Failed to get policy snapshot")
	policySnapshot.Labels[placementv1beta1.IsLatestSnapshotLabel] = strconv.FormatBool(false)
	Expect(hubClient.Update(ctx, policySnapshot)).To(Succeed(), "Failed to update policy snapshot")

	// Create a new policy snapshot.
	policySnapshot = &placementv1beta1.ClusterSchedulingPolicySnapshot{
		ObjectMeta: metav1.ObjectMeta{
			Name: newPolicySnapshotName,
			Labels: map[string]string{
				placementv1beta1.IsLatestSnapshotLabel: strconv.FormatBool(true),
				placementv1beta1.CRPTrackingLabel:      crpName,
			},
			Annotations: map[string]string{
				placementv1beta1.CRPGenerationAnnotation:    strconv.FormatInt(crpGeneration, 10),
				placementv1beta1.NumberOfClustersAnnotation: strconv.FormatInt(int64(*numOfClusters), 10),
			},
		},
		Spec: placementv1beta1.SchedulingPolicySnapshotSpec{
			Policy:     policy,
			PolicyHash: []byte(policyHash),
		},
	}
	Expect(hubClient.Create(ctx, policySnapshot)).To(Succeed(), "Failed to create policy snapshot")
}
